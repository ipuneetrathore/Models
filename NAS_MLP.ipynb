{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.5'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras import optimizers\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.models import Model\n",
    "from keras.engine.input_layer import Input\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "#                   NAS PARAMETERS                     #\n",
    "########################################################\n",
    "CONTROLLER_SAMPLING_EPOCHS = 10\n",
    "SAMPLES_PER_CONTROLLER_EPOCH = 10\n",
    "CONTROLLER_TRAINING_EPOCHS = 10\n",
    "ARCHITECTURE_TRAINING_EPOCHS = 10\n",
    "CONTROLLER_LOSS_ALPHA = 0.9\n",
    "\n",
    "########################################################\n",
    "#               CONTROLLER PARAMETERS                  #\n",
    "########################################################\n",
    "CONTROLLER_LSTM_DIM = 100\n",
    "CONTROLLER_OPTIMIZER = 'Adam'\n",
    "CONTROLLER_LEARNING_RATE = 0.01\n",
    "CONTROLLER_DECAY = 0.1\n",
    "CONTROLLER_MOMENTUM = 0.0\n",
    "CONTROLLER_USE_PREDICTOR = True\n",
    "\n",
    "########################################################\n",
    "#                   MLP PARAMETERS                     #\n",
    "########################################################\n",
    "MAX_ARCHITECTURE_LENGTH = 3\n",
    "MLP_OPTIMIZER = 'Adam'\n",
    "MLP_LEARNING_RATE = 0.01\n",
    "MLP_DECAY = 0.0\n",
    "MLP_MOMENTUM = 0.0\n",
    "MLP_DROPOUT = 0.2\n",
    "MLP_LOSS_FUNCTION = 'categorical_crossentropy'\n",
    "MLP_ONE_SHOT = True\n",
    "\n",
    "########################################################\n",
    "#                   DATA PARAMETERS                    #\n",
    "########################################################\n",
    "TARGET_CLASSES = 7\n",
    "\n",
    "########################################################\n",
    "#                  OUTPUT PARAMETERS                   #\n",
    "########################################################\n",
    "TOP_N = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPSearchSpace(object):\n",
    "\n",
    "    def __init__(self, target_classes):\n",
    "\n",
    "        self.target_classes = target_classes\n",
    "        self.vocab = self.vocab_dict()\n",
    "\n",
    "    def vocab_dict(self):\n",
    "        nodes = [8, 16, 32, 64, 128, 256, 512]\n",
    "        act_funcs = ['sigmoid', 'tanh', 'relu', 'elu']\n",
    "        layer_params = []\n",
    "        layer_id = []\n",
    "        for i in range(len(nodes)):\n",
    "            for j in range(len(act_funcs)):\n",
    "                layer_params.append((nodes[i], act_funcs[j]))\n",
    "                layer_id.append(len(act_funcs) * i + j + 1)\n",
    "        vocab = dict(zip(layer_id, layer_params))\n",
    "        vocab[len(vocab) + 1] = (('dropout'))\n",
    "        if self.target_classes == 2:\n",
    "            vocab[len(vocab) + 1] = (self.target_classes - 1, 'sigmoid')\n",
    "        else:\n",
    "            vocab[len(vocab) + 1] = (self.target_classes, 'softmax')\n",
    "        return vocab\n",
    "\n",
    "    def encode_sequence(self, sequence):\n",
    "        keys = list(self.vocab.keys())\n",
    "        values = list(self.vocab.values())\n",
    "        encoded_sequence = []\n",
    "        for value in sequence:\n",
    "            encoded_sequence.append(keys[values.index(value)])\n",
    "        return encoded_sequence\n",
    "\n",
    "    def decode_sequence(self, sequence):\n",
    "        keys = list(self.vocab.keys())\n",
    "        values = list(self.vocab.values())\n",
    "        decoded_sequence = []\n",
    "        for key in sequence:\n",
    "            decoded_sequence.append(values[keys.index(key)])\n",
    "        return decoded_sequence\n",
    "\n",
    "\n",
    "class MLPGenerator(MLPSearchSpace):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.target_classes = TARGET_CLASSES\n",
    "        self.mlp_optimizer = MLP_OPTIMIZER\n",
    "        self.mlp_lr = MLP_LEARNING_RATE\n",
    "        self.mlp_decay = MLP_DECAY\n",
    "        self.mlp_momentum = MLP_MOMENTUM\n",
    "        self.mlp_dropout = MLP_DROPOUT\n",
    "        self.mlp_loss_func = MLP_LOSS_FUNCTION\n",
    "        self.mlp_one_shot = MLP_ONE_SHOT\n",
    "        self.metrics = ['accuracy']\n",
    "\n",
    "        super().__init__(TARGET_CLASSES)\n",
    "\n",
    "\n",
    "        if self.mlp_one_shot:\n",
    "            self.weights_file = 'LOGS/shared_weights.pkl'\n",
    "            self.shared_weights = pd.DataFrame({'bigram_id': [], 'weights': []})\n",
    "            if not os.path.exists(self.weights_file):\n",
    "                print(\"Initializing shared weights dictionary...\")\n",
    "                self.shared_weights.to_pickle(self.weights_file)\n",
    "\n",
    "    def create_model(self, sequence, mlp_input_shape):\n",
    "        layer_configs = self.decode_sequence(sequence)\n",
    "        model = Sequential()\n",
    "        if len(mlp_input_shape) > 1:\n",
    "            model.add(Flatten(name='flatten', input_shape=mlp_input_shape))\n",
    "            for i, layer_conf in enumerate(layer_configs):\n",
    "                if layer_conf is 'dropout':\n",
    "                    model.add(Dropout(self.mlp_dropout, name='dropout'))\n",
    "                else:\n",
    "                    model.add(Dense(units=layer_conf[0], activation=layer_conf[1]))\n",
    "        else:\n",
    "            for i, layer_conf in enumerate(layer_configs):\n",
    "                if i == 0:\n",
    "                    model.add(Dense(units=layer_conf[0], activation=layer_conf[1], input_shape=mlp_input_shape))\n",
    "                elif layer_conf is 'dropout':\n",
    "                    model.add(Dropout(self.mlp_dropout, name='dropout'))\n",
    "                else:\n",
    "                    model.add(Dense(units=layer_conf[0], activation=layer_conf[1]))\n",
    "        return model\n",
    "\n",
    "    def compile_model(self, model):\n",
    "        if self.mlp_optimizer == 'sgd':\n",
    "            optim = optimizers.SGD(lr=self.mlp_lr, decay=self.mlp_decay, momentum=self.mlp_momentum)\n",
    "        else:\n",
    "            optim = getattr(optimizers, self.mlp_optimizer)(lr=self.mlp_lr, decay=self.mlp_decay)\n",
    "        model.compile(loss=self.mlp_loss_func, optimizer=optim, metrics=self.metrics)\n",
    "        return model\n",
    "\n",
    "    def update_weights(self, model):\n",
    "        layer_configs = ['input']\n",
    "        for layer in model.layers:\n",
    "            if 'flatten' in layer.name:\n",
    "                layer_configs.append(('flatten'))\n",
    "            elif 'dropout' not in layer.name:\n",
    "                layer_configs.append((layer.get_config()['units'], layer.get_config()['activation']))\n",
    "        config_ids = []\n",
    "        for i in range(1, len(layer_configs)):\n",
    "            config_ids.append((layer_configs[i - 1], layer_configs[i]))\n",
    "        j = 0\n",
    "        for i, layer in enumerate(model.layers):\n",
    "            if 'dropout' not in layer.name:\n",
    "                warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "                bigram_ids = self.shared_weights['bigram_id'].values\n",
    "                search_index = []\n",
    "                for i in range(len(bigram_ids)):\n",
    "                    if config_ids[j] == bigram_ids[i]:\n",
    "                        search_index.append(i)\n",
    "                if len(search_index) == 0:\n",
    "                    self.shared_weights = self.shared_weights.append({'bigram_id': config_ids[j],\n",
    "                                                                      'weights': layer.get_weights()},\n",
    "                                                                     ignore_index=True)\n",
    "                else:\n",
    "                    self.shared_weights.at[search_index[0], 'weights'] = layer.get_weights()\n",
    "                j += 1\n",
    "        self.shared_weights.to_pickle(self.weights_file)\n",
    "\n",
    "    def set_model_weights(self, model):\n",
    "        layer_configs = ['input']\n",
    "        for layer in model.layers:\n",
    "            if 'flatten' in layer.name:\n",
    "                layer_configs.append(('flatten'))\n",
    "            elif 'dropout' not in layer.name:\n",
    "                layer_configs.append((layer.get_config()['units'], layer.get_config()['activation']))\n",
    "        config_ids = []\n",
    "        for i in range(1, len(layer_configs)):\n",
    "            config_ids.append((layer_configs[i - 1], layer_configs[i]))\n",
    "        j = 0\n",
    "        for i, layer in enumerate(model.layers):\n",
    "            if 'dropout' not in layer.name:\n",
    "                warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "                bigram_ids = self.shared_weights['bigram_id'].values\n",
    "                search_index = []\n",
    "                for i in range(len(bigram_ids)):\n",
    "                    if config_ids[j] == bigram_ids[i]:\n",
    "                        search_index.append(i)\n",
    "                if len(search_index) > 0:\n",
    "                    print(\"Transferring weights for layer:\", config_ids[j])\n",
    "                    layer.set_weights(self.shared_weights['weights'].values[search_index[0]])\n",
    "                j += 1\n",
    "\n",
    "    def train_model(self, model, x_data, y_data, nb_epochs, validation_split=0.1, callbacks=None):\n",
    "        if self.mlp_one_shot:\n",
    "            self.set_model_weights(model)\n",
    "            history = model.fit(x_data,\n",
    "                                y_data,\n",
    "                                epochs=nb_epochs,\n",
    "                                validation_split=validation_split,\n",
    "                                callbacks=callbacks,\n",
    "                                verbose=0)\n",
    "            self.update_weights(model)\n",
    "        else:\n",
    "            history = model.fit(x_data,\n",
    "                                y_data,\n",
    "                                epochs=nb_epochs,\n",
    "                                validation_split=validation_split,\n",
    "                                callbacks=callbacks,\n",
    "                                verbose=0)\n",
    "        return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Controller(MLPSearchSpace):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.max_len = MAX_ARCHITECTURE_LENGTH\n",
    "        self.controller_lstm_dim = CONTROLLER_LSTM_DIM\n",
    "        self.controller_optimizer = CONTROLLER_OPTIMIZER\n",
    "        self.controller_lr = CONTROLLER_LEARNING_RATE\n",
    "        self.controller_decay = CONTROLLER_DECAY\n",
    "        self.controller_momentum = CONTROLLER_MOMENTUM\n",
    "        self.use_predictor = CONTROLLER_USE_PREDICTOR\n",
    "\n",
    "        self.controller_weights = 'LOGS/controller_weights.h5'\n",
    "\n",
    "        self.seq_data = []\n",
    "\n",
    "        super().__init__(TARGET_CLASSES)\n",
    "\n",
    "        self.controller_classes = len(self.vocab) + 1\n",
    "\n",
    "    def sample_architecture_sequences(self, model, number_of_samples):\n",
    "        final_layer_id = len(self.vocab)\n",
    "        dropout_id = final_layer_id - 1\n",
    "        vocab_idx = [0] + list(self.vocab.keys())\n",
    "        samples = []\n",
    "        print(\"GENERATING ARCHITECTURE SAMPLES...\")\n",
    "        print('------------------------------------------------------')\n",
    "        while len(samples) < number_of_samples:\n",
    "            seed = []\n",
    "            while len(seed) < self.max_len:\n",
    "                sequence = pad_sequences([seed], maxlen=self.max_len - 1, padding='post')\n",
    "                sequence = sequence.reshape(1, 1, self.max_len - 1)\n",
    "                if self.use_predictor:\n",
    "                    (probab, _) = model.predict(sequence)\n",
    "                else:\n",
    "                    probab = model.predict(sequence)\n",
    "                probab = probab[0][0]\n",
    "                next = np.random.choice(vocab_idx, size=1, p=probab)[0]\n",
    "                if next == dropout_id and len(seed) == 0:\n",
    "                    continue\n",
    "                if next == final_layer_id and len(seed) == 0:\n",
    "                    continue\n",
    "                if next == final_layer_id:\n",
    "                    seed.append(next)\n",
    "                    break\n",
    "                if len(seed) == self.max_len - 1:\n",
    "                    seed.append(final_layer_id)\n",
    "                    break\n",
    "                if not next == 0:\n",
    "                    seed.append(next)\n",
    "            if seed not in self.seq_data:\n",
    "                samples.append(seed)\n",
    "                self.seq_data.append(seed)\n",
    "        return samples\n",
    "\n",
    "    def control_model(self, controller_input_shape, controller_batch_size):\n",
    "        main_input = Input(shape=controller_input_shape, batch_shape=controller_batch_size, name='main_input')\n",
    "        x = LSTM(self.controller_lstm_dim, return_sequences=True)(main_input)\n",
    "        main_output = Dense(self.controller_classes, activation='softmax', name='main_output')(x)\n",
    "        model = Model(inputs=[main_input], outputs=[main_output])\n",
    "        return model\n",
    "\n",
    "    def train_control_model(self, model, x_data, y_data, loss_func, controller_batch_size, nb_epochs):\n",
    "        if self.controller_optimizer == 'sgd':\n",
    "            optim = optimizers.SGD(lr=self.controller_lr, decay=self.controller_decay, momentum=self.controller_momentum, clipnorm=1.0)\n",
    "        else:\n",
    "            optim = getattr(optimizers, self.controller_optimizer)(lr=self.controller_lr, decay=self.controller_decay, clipnorm=1.0)\n",
    "        model.compile(optimizer=optim, loss={'main_output': loss_func})\n",
    "        if os.path.exists(self.controller_weights):\n",
    "            model.load_weights(self.controller_weights)\n",
    "        print(\"TRAINING CONTROLLER...\")\n",
    "        model.fit({'main_input': x_data},\n",
    "                  {'main_output': y_data.reshape(len(y_data), 1, self.controller_classes)},\n",
    "                  epochs=nb_epochs,\n",
    "                  batch_size=controller_batch_size,\n",
    "                  verbose=0)\n",
    "        model.save_weights(self.controller_weights)\n",
    "\n",
    "    def hybrid_control_model(self, controller_input_shape, controller_batch_size):\n",
    "        main_input = Input(shape=controller_input_shape, batch_shape=controller_batch_size, name='main_input')\n",
    "        x = LSTM(self.controller_lstm_dim, return_sequences=True)(main_input)\n",
    "        predictor_output = Dense(1, activation='sigmoid', name='predictor_output')(x)\n",
    "        main_output = Dense(self.controller_classes, activation='softmax', name='main_output')(x)\n",
    "        model = Model(inputs=[main_input], outputs=[main_output, predictor_output])\n",
    "        return model\n",
    "\n",
    "    def train_hybrid_model(self, model, x_data, y_data, pred_target, loss_func, controller_batch_size, nb_epochs):\n",
    "        if self.controller_optimizer == 'sgd':\n",
    "            optim = optimizers.SGD(lr=self.controller_lr, decay=self.controller_decay, momentum=self.controller_momentum, clipnorm=1.0)\n",
    "        else:\n",
    "            optim = getattr(optimizers, self.controller_optimizer)(lr=self.controller_lr, decay=self.controller_decay, clipnorm=1.0)\n",
    "        model.compile(optimizer=optim,\n",
    "                      loss={'main_output': loss_func, 'predictor_output': 'mse'},\n",
    "                      loss_weights={'main_output': 1, 'predictor_output': 1})\n",
    "        if os.path.exists(self.controller_weights):\n",
    "            model.load_weights(self.controller_weights)\n",
    "        print(\"TRAINING CONTROLLER...\")\n",
    "        model.fit({'main_input': x_data},\n",
    "                  {'main_output': y_data.reshape(len(y_data), 1, self.controller_classes),\n",
    "                   'predictor_output': np.array(pred_target).reshape(len(pred_target), 1, 1)},\n",
    "                  epochs=nb_epochs,\n",
    "                  batch_size=controller_batch_size,\n",
    "                  verbose=0)\n",
    "        model.save_weights(self.controller_weights)\n",
    "\n",
    "    def get_predicted_accuracies_hybrid_model(self, model, seqs):\n",
    "        pred_accuracies = []\n",
    "        for seq in seqs:\n",
    "            control_sequences = pad_sequences([seq], maxlen=self.max_len, padding='post')\n",
    "            xc = control_sequences[:, :-1].reshape(len(control_sequences), 1, self.max_len - 1)\n",
    "            (_, pred_accuracy) = [x[0][0] for x in model.predict(xc)]\n",
    "            pred_accuracies.append(pred_accuracy[0])\n",
    "        return pred_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import keras.backend as K\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPNAS(Controller):\n",
    "\n",
    "    def __init__(self, x, y):\n",
    "\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.target_classes = TARGET_CLASSES\n",
    "        self.controller_sampling_epochs = CONTROLLER_SAMPLING_EPOCHS\n",
    "        self.samples_per_controller_epoch = SAMPLES_PER_CONTROLLER_EPOCH\n",
    "        self.controller_train_epochs = CONTROLLER_TRAINING_EPOCHS\n",
    "        self.architecture_train_epochs = ARCHITECTURE_TRAINING_EPOCHS\n",
    "        self.controller_loss_alpha = CONTROLLER_LOSS_ALPHA\n",
    "\n",
    "        self.data = []\n",
    "        self.nas_data_log = 'LOGS/nas_data.pkl'\n",
    "        clean_log()\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.model_generator = MLPGenerator()\n",
    "\n",
    "        self.controller_batch_size = len(self.data)\n",
    "        self.controller_input_shape = (1, MAX_ARCHITECTURE_LENGTH - 1)\n",
    "        if self.use_predictor:\n",
    "            self.controller_model = self.hybrid_control_model(self.controller_input_shape, self.controller_batch_size)\n",
    "        else:\n",
    "            self.controller_model = self.control_model(self.controller_input_shape, self.controller_batch_size)\n",
    "\n",
    "    def create_architecture(self, sequence):\n",
    "        if self.target_classes == 2:\n",
    "            self.model_generator.loss_func = 'binary_crossentropy'\n",
    "        model = self.model_generator.create_model(sequence, np.shape(self.x[0]))\n",
    "        model = self.model_generator.compile_model(model)\n",
    "        return model\n",
    "\n",
    "    def train_architecture(self, model):\n",
    "        x, y = unison_shuffled_copies(self.x, self.y)\n",
    "        history = self.model_generator.train_model(model, x, y, self.architecture_train_epochs)\n",
    "        return history\n",
    "\n",
    "    def append_model_metrics(self, sequence, history, pred_accuracy=None):\n",
    "        if len(history.history['val_acc']) == 1:\n",
    "            if pred_accuracy:\n",
    "                self.data.append([sequence,\n",
    "                                  history.history['val_acc'][0],\n",
    "                                  pred_accuracy])\n",
    "            else:\n",
    "                self.data.append([sequence,\n",
    "                                  history.history['val_acc'][0]])\n",
    "            print('validation accuracy: ', history.history['val_accuracy'][0])\n",
    "        else:\n",
    "            val_acc = np.ma.average(history.history['val_acc'],\n",
    "                                    weights=np.arange(1, len(history.history['val_acc']) + 1),\n",
    "                                    axis=-1)\n",
    "            if pred_accuracy:\n",
    "                self.data.append([sequence,\n",
    "                                  val_acc,\n",
    "                                  pred_accuracy])\n",
    "            else:\n",
    "                self.data.append([sequence,\n",
    "                                  val_acc])\n",
    "            print('validation accuracy: ', val_acc)\n",
    "\n",
    "    def prepare_controller_data(self, sequences):\n",
    "        controller_sequences = pad_sequences(sequences, maxlen=self.max_len, padding='post')\n",
    "        xc = controller_sequences[:, :-1].reshape(len(controller_sequences), 1, self.max_len - 1)\n",
    "        yc = to_categorical(controller_sequences[:, -1], self.controller_classes)\n",
    "        val_acc_target = [item[1] for item in self.data]\n",
    "        return xc, yc, val_acc_target\n",
    "\n",
    "    def get_discounted_reward(self, rewards):\n",
    "        discounted_r = np.zeros_like(rewards, dtype=np.float32)\n",
    "        for t in range(len(rewards)):\n",
    "            running_add = 0.\n",
    "            exp = 0.\n",
    "            for r in rewards[t:]:\n",
    "                running_add += self.controller_loss_alpha**exp * r\n",
    "                exp += 1\n",
    "            discounted_r[t] = running_add\n",
    "        discounted_r = (discounted_r - discounted_r.mean()) / discounted_r.std()\n",
    "        return discounted_r\n",
    "\n",
    "    def custom_loss(self, target, output):\n",
    "        baseline = 0.5\n",
    "        reward = np.array([item[1] - baseline for item in self.data[-self.samples_per_controller_epoch:]]).reshape(\n",
    "            self.samples_per_controller_epoch, 1)\n",
    "        discounted_reward = self.get_discounted_reward(reward)\n",
    "        loss = - K.log(output) * discounted_reward[:, None]\n",
    "        return loss\n",
    "\n",
    "    def train_controller(self, model, x, y, pred_accuracy=None):\n",
    "        if self.use_predictor:\n",
    "            self.train_hybrid_model(model,\n",
    "                                    x,\n",
    "                                    y,\n",
    "                                    pred_accuracy,\n",
    "                                    self.custom_loss,\n",
    "                                    len(self.data),\n",
    "                                    self.controller_train_epochs)\n",
    "        else:\n",
    "            self.train_control_model(model,\n",
    "                                     x,\n",
    "                                     y,\n",
    "                                     self.custom_loss,\n",
    "                                     len(self.data),\n",
    "                                     self.controller_train_epochs)\n",
    "\n",
    "    def search(self):\n",
    "        for controller_epoch in range(self.controller_sampling_epochs):\n",
    "            print('------------------------------------------------------------------')\n",
    "            print('                       CONTROLLER EPOCH: {}'.format(controller_epoch))\n",
    "            print('------------------------------------------------------------------')\n",
    "            sequences = self.sample_architecture_sequences(self.controller_model, self.samples_per_controller_epoch)\n",
    "            if self.use_predictor:\n",
    "                pred_accuracies = self.get_predicted_accuracies_hybrid_model(self.controller_model, sequences)\n",
    "            for i, sequence in enumerate(sequences):\n",
    "                print('Architecture: ', self.decode_sequence(sequence))\n",
    "                model = self.create_architecture(sequence)\n",
    "                history = self.train_architecture(model)\n",
    "                if self.use_predictor:\n",
    "                    self.append_model_metrics(sequence, history, pred_accuracies[i])\n",
    "                else:\n",
    "                    self.append_model_metrics(sequence, history)\n",
    "                print('------------------------------------------------------')\n",
    "            xc, yc, val_acc_target = self.prepare_controller_data(sequences)\n",
    "            self.train_controller(self.controller_model,\n",
    "                                  xc,\n",
    "                                  yc,\n",
    "                                  val_acc_target[-self.samples_per_controller_epoch:])\n",
    "        with open(self.nas_data_log, 'wb') as f:\n",
    "            pickle.dump(self.data, f)\n",
    "        log_event()\n",
    "        return self.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pickle\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "#                   DATA PROCESSING                    #\n",
    "########################################################\n",
    "\n",
    "\n",
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]\n",
    "\n",
    "\n",
    "########################################################\n",
    "#                       LOGGING                        #\n",
    "########################################################\n",
    "\n",
    "\n",
    "def clean_log():\n",
    "    filelist = os.listdir('LOGS')\n",
    "    for file in filelist:\n",
    "        if os.path.isfile('LOGS/{}'.format(file)):\n",
    "            os.remove('LOGS/{}'.format(file))\n",
    "\n",
    "\n",
    "def log_event():\n",
    "    dest = 'LOGS'\n",
    "    while os.path.exists(dest):\n",
    "        dest = 'LOGS/event{}'.format(np.random.randint(10000))\n",
    "    os.mkdir(dest)\n",
    "    filelist = os.listdir('LOGS')\n",
    "    for file in filelist:\n",
    "        if os.path.isfile('LOGS/{}'.format(file)):\n",
    "            shutil.move('LOGS/{}'.format(file),dest)\n",
    "\n",
    "\n",
    "def get_latest_event_id():\n",
    "    all_subdirs = ['LOGS/' + d for d in os.listdir('LOGS') if os.path.isdir('LOGS/' + d)]\n",
    "    latest_subdir = max(all_subdirs, key=os.path.getmtime)\n",
    "    return int(latest_subdir.replace('LOGS/event', ''))\n",
    "\n",
    "\n",
    "########################################################\n",
    "#                 RESULTS PROCESSING                   #\n",
    "########################################################\n",
    "\n",
    "\n",
    "def load_nas_data():\n",
    "    event = get_latest_event_id()\n",
    "    data_file = 'LOGS/event{}/nas_data.pkl'.format(event)\n",
    "    with open(data_file, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "\n",
    "def sort_search_data(nas_data):\n",
    "    val_accs = [item[1] for item in nas_data]\n",
    "    sorted_idx = np.argsort(val_accs)[::-1]\n",
    "    nas_data = [nas_data[x] for x in sorted_idx]\n",
    "    return nas_data\n",
    "\n",
    "########################################################\n",
    "#                EVALUATION AND PLOTS                  #\n",
    "########################################################\n",
    "\n",
    "def get_top_n_architectures(n):\n",
    "    data = load_nas_data()\n",
    "    data = sort_search_data(data)\n",
    "    search_space = MLPSearchSpace(TARGET_CLASSES)\n",
    "    print('Top {} Architectures:'.format(n))\n",
    "    for seq_data in data[:n]:\n",
    "        print('Architecture', search_space.decode_sequence(seq_data[0]))\n",
    "        print('Validation Accuracy:', seq_data[1])\n",
    "\n",
    "\n",
    "def get_nas_accuracy_plot():\n",
    "    data = load_nas_data()\n",
    "    accuracies = [x[1] for x in data]\n",
    "    plt.plot(np.arange(len(data)), accuracies)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_accuracy_distribution():\n",
    "    event = get_latest_event_id()\n",
    "    data = load_nas_data()\n",
    "    accuracies = [x[1]*100. for x in data]\n",
    "    accuracies = [int(x) for x in accuracies]\n",
    "    sorted_accs = np.sort(accuracies)\n",
    "    count_dict = {k: len(list(v)) for k, v in groupby(sorted_accs)}\n",
    "    plt.bar(list(count_dict.keys()), list(count_dict.values()))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing shared weights dictionary...\n",
      "------------------------------------------------------------------\n",
      "                       CONTROLLER EPOCH: 0\n",
      "------------------------------------------------------------------\n",
      "GENERATING ARCHITECTURE SAMPLES...\n",
      "------------------------------------------------------\n",
      "Architecture:  [(512, 'tanh'), (256, 'relu'), (7, 'softmax')]\n",
      "validation accuracy:  0.984498432601881\n",
      "------------------------------------------------------\n",
      "Architecture:  [(16, 'tanh'), (8, 'relu'), (7, 'softmax')]\n",
      "validation accuracy:  0.9774733542319749\n",
      "------------------------------------------------------\n",
      "Architecture:  [(32, 'tanh'), (32, 'elu'), (7, 'softmax')]\n",
      "validation accuracy:  0.9843260188087773\n",
      "------------------------------------------------------\n",
      "Architecture:  [(64, 'relu'), (256, 'relu'), (7, 'softmax')]\n",
      "Transferring weights for layer: ((256, 'relu'), (7, 'softmax'))\n",
      "validation accuracy:  0.7867241379310345\n",
      "------------------------------------------------------\n",
      "Architecture:  [(8, 'tanh'), (128, 'elu'), (7, 'softmax')]\n",
      "validation accuracy:  0.9849592476489029\n",
      "------------------------------------------------------\n",
      "Architecture:  [(64, 'tanh'), (7, 'softmax')]\n",
      "validation accuracy:  0.9872413793103447\n",
      "------------------------------------------------------\n",
      "Architecture:  [(8, 'elu'), (256, 'sigmoid'), (7, 'softmax')]\n",
      "validation accuracy:  0.9827962382445141\n",
      "------------------------------------------------------\n",
      "Architecture:  [(512, 'elu'), (64, 'sigmoid'), (7, 'softmax')]\n",
      "validation accuracy:  0.9064952978056425\n",
      "------------------------------------------------------\n",
      "Architecture:  [(512, 'tanh'), (64, 'sigmoid'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (512, 'tanh'))\n",
      "Transferring weights for layer: ((64, 'sigmoid'), (7, 'softmax'))\n",
      "validation accuracy:  0.8723667711598747\n",
      "------------------------------------------------------\n",
      "Architecture:  [(32, 'sigmoid'), (512, 'relu'), (7, 'softmax')]\n",
      "validation accuracy:  0.9939874608150471\n",
      "------------------------------------------------------\n",
      "TRAINING CONTROLLER...\n",
      "------------------------------------------------------------------\n",
      "                       CONTROLLER EPOCH: 1\n",
      "------------------------------------------------------------------\n",
      "GENERATING ARCHITECTURE SAMPLES...\n",
      "------------------------------------------------------\n",
      "Architecture:  [(128, 'sigmoid'), (8, 'sigmoid'), (7, 'softmax')]\n",
      "validation accuracy:  0.9939717868338558\n",
      "------------------------------------------------------\n",
      "Architecture:  [(32, 'sigmoid'), (8, 'relu'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (32, 'sigmoid'))\n",
      "Transferring weights for layer: ((8, 'relu'), (7, 'softmax'))\n",
      "validation accuracy:  0.9955485893416928\n",
      "------------------------------------------------------\n",
      "Architecture:  [(8, 'relu'), (8, 'relu'), (7, 'softmax')]\n",
      "Transferring weights for layer: ((8, 'relu'), (7, 'softmax'))\n",
      "validation accuracy:  0.7932758620689654\n",
      "------------------------------------------------------\n",
      "Architecture:  [(256, 'tanh'), (8, 'relu'), (7, 'softmax')]\n",
      "Transferring weights for layer: ((8, 'relu'), (7, 'softmax'))\n",
      "validation accuracy:  0.9805266457680251\n",
      "------------------------------------------------------\n",
      "Architecture:  [(512, 'sigmoid'), (512, 'sigmoid'), (7, 'softmax')]\n",
      "validation accuracy:  0.9255987460815047\n",
      "------------------------------------------------------\n",
      "Architecture:  [(16, 'sigmoid'), (7, 'softmax')]\n",
      "validation accuracy:  0.9970564263322885\n",
      "------------------------------------------------------\n",
      "Architecture:  [(256, 'tanh'), (64, 'elu'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (256, 'tanh'))\n",
      "validation accuracy:  0.9879529780564263\n",
      "------------------------------------------------------\n",
      "Architecture:  [(128, 'relu'), (512, 'relu'), (7, 'softmax')]\n",
      "Transferring weights for layer: ((512, 'relu'), (7, 'softmax'))\n",
      "validation accuracy:  0.7827586206896552\n",
      "------------------------------------------------------\n",
      "Architecture:  [(8, 'elu'), (64, 'elu'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (8, 'elu'))\n",
      "Transferring weights for layer: ((64, 'elu'), (7, 'softmax'))\n",
      "validation accuracy:  0.9687774294670847\n",
      "------------------------------------------------------\n",
      "Architecture:  [(512, 'tanh'), (32, 'elu'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (512, 'tanh'))\n",
      "Transferring weights for layer: ((32, 'elu'), (7, 'softmax'))\n",
      "validation accuracy:  0.7846363636363637\n",
      "------------------------------------------------------\n",
      "TRAINING CONTROLLER...\n",
      "------------------------------------------------------------------\n",
      "                       CONTROLLER EPOCH: 2\n",
      "------------------------------------------------------------------\n",
      "GENERATING ARCHITECTURE SAMPLES...\n",
      "------------------------------------------------------\n",
      "Architecture:  [(8, 'elu'), (512, 'sigmoid'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (8, 'elu'))\n",
      "Transferring weights for layer: ((512, 'sigmoid'), (7, 'softmax'))\n",
      "validation accuracy:  0.9348432601880877\n",
      "------------------------------------------------------\n",
      "Architecture:  [(64, 'elu'), (8, 'elu'), (7, 'softmax')]\n",
      "validation accuracy:  0.9951755485893418\n",
      "------------------------------------------------------\n",
      "Architecture:  [(64, 'sigmoid'), (128, 'tanh'), (7, 'softmax')]\n",
      "validation accuracy:  0.9963824451410659\n",
      "------------------------------------------------------\n",
      "Architecture:  [(32, 'tanh'), (128, 'sigmoid'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (32, 'tanh'))\n",
      "validation accuracy:  0.9864639498432601\n",
      "------------------------------------------------------\n",
      "Architecture:  [(512, 'relu'), (8, 'tanh'), (7, 'softmax')]\n",
      "validation accuracy:  0.7796551724137931\n",
      "------------------------------------------------------\n",
      "Architecture:  [(512, 'relu'), (128, 'elu'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (512, 'relu'))\n",
      "Transferring weights for layer: ((128, 'elu'), (7, 'softmax'))\n",
      "validation accuracy:  0.14482758620689656\n",
      "------------------------------------------------------\n",
      "Architecture:  [(256, 'sigmoid'), 'dropout', (7, 'softmax')]\n",
      "Transferring weights for layer: ((256, 'sigmoid'), (7, 'softmax'))\n",
      "validation accuracy:  0.9909686520376174\n",
      "------------------------------------------------------\n",
      "Architecture:  [(32, 'elu'), (7, 'softmax')]\n",
      "Transferring weights for layer: ((32, 'elu'), (7, 'softmax'))\n",
      "validation accuracy:  0.05794984326018809\n",
      "------------------------------------------------------\n",
      "Architecture:  [(32, 'elu'), (512, 'relu'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (32, 'elu'))\n",
      "Transferring weights for layer: ((512, 'relu'), (7, 'softmax'))\n",
      "validation accuracy:  0.7886206896551725\n",
      "------------------------------------------------------\n",
      "Architecture:  [(256, 'elu'), (8, 'tanh'), (7, 'softmax')]\n",
      "Transferring weights for layer: ((8, 'tanh'), (7, 'softmax'))\n",
      "validation accuracy:  0.8004263322884012\n",
      "------------------------------------------------------\n",
      "TRAINING CONTROLLER...\n",
      "------------------------------------------------------------------\n",
      "                       CONTROLLER EPOCH: 3\n",
      "------------------------------------------------------------------\n",
      "GENERATING ARCHITECTURE SAMPLES...\n",
      "------------------------------------------------------\n",
      "Architecture:  [(32, 'sigmoid'), (32, 'relu'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (32, 'sigmoid'))\n",
      "validation accuracy:  0.9927868338557995\n",
      "------------------------------------------------------\n",
      "Architecture:  [(32, 'tanh'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (32, 'tanh'))\n",
      "validation accuracy:  0.9941692789968651\n",
      "------------------------------------------------------\n",
      "Architecture:  [(8, 'elu'), (32, 'tanh'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (8, 'elu'))\n",
      "Transferring weights for layer: ((32, 'tanh'), (7, 'softmax'))\n",
      "validation accuracy:  0.9924514106583072\n",
      "------------------------------------------------------\n",
      "Architecture:  [(8, 'sigmoid'), (512, 'elu'), (7, 'softmax')]\n",
      "validation accuracy:  0.9903573667711599\n",
      "------------------------------------------------------\n",
      "Architecture:  [(512, 'relu'), (256, 'elu'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (512, 'relu'))\n",
      "validation accuracy:  0.786551724137931\n",
      "------------------------------------------------------\n",
      "Architecture:  [(64, 'sigmoid'), (16, 'tanh'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (64, 'sigmoid'))\n",
      "validation accuracy:  0.9943510971786834\n",
      "------------------------------------------------------\n",
      "Architecture:  [(256, 'elu'), (256, 'tanh'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (256, 'elu'))\n",
      "validation accuracy:  0.852\n",
      "------------------------------------------------------\n",
      "Architecture:  [(512, 'tanh'), (512, 'tanh'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (512, 'tanh'))\n",
      "validation accuracy:  0.8090501567398118\n",
      "------------------------------------------------------\n",
      "Architecture:  [(512, 'tanh'), (32, 'tanh'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (512, 'tanh'))\n",
      "Transferring weights for layer: ((32, 'tanh'), (7, 'softmax'))\n",
      "validation accuracy:  0.8202758620689654\n",
      "------------------------------------------------------\n",
      "Architecture:  [(32, 'sigmoid'), (8, 'elu'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (32, 'sigmoid'))\n",
      "Transferring weights for layer: ((8, 'elu'), (7, 'softmax'))\n",
      "validation accuracy:  0.9912225705329154\n",
      "------------------------------------------------------\n",
      "TRAINING CONTROLLER...\n",
      "------------------------------------------------------------------\n",
      "                       CONTROLLER EPOCH: 4\n",
      "------------------------------------------------------------------\n",
      "GENERATING ARCHITECTURE SAMPLES...\n",
      "------------------------------------------------------\n",
      "Architecture:  [(512, 'elu'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (512, 'elu'))\n",
      "Transferring weights for layer: ((512, 'elu'), (7, 'softmax'))\n",
      "validation accuracy:  0.0003448275862068965\n",
      "------------------------------------------------------\n",
      "Architecture:  [(512, 'tanh'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (512, 'tanh'))\n",
      "Transferring weights for layer: ((512, 'tanh'), (7, 'softmax'))\n",
      "validation accuracy:  0.9755454545454546\n",
      "------------------------------------------------------\n",
      "Architecture:  [(8, 'elu'), (32, 'elu'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (8, 'elu'))\n",
      "Transferring weights for layer: ((32, 'elu'), (7, 'softmax'))\n",
      "validation accuracy:  0.9945830721003135\n",
      "------------------------------------------------------\n",
      "Architecture:  [(16, 'elu'), (16, 'relu'), (7, 'softmax')]\n",
      "validation accuracy:  0.993871473354232\n",
      "------------------------------------------------------\n",
      "Architecture:  [(512, 'relu'), (16, 'relu'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (512, 'relu'))\n",
      "Transferring weights for layer: ((16, 'relu'), (7, 'softmax'))\n",
      "validation accuracy:  0.7841379310344826\n",
      "------------------------------------------------------\n",
      "Architecture:  [(512, 'elu'), (512, 'tanh'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (512, 'elu'))\n",
      "Transferring weights for layer: ((512, 'tanh'), (7, 'softmax'))\n",
      "validation accuracy:  0.7820689655172415\n",
      "------------------------------------------------------\n",
      "Architecture:  [(16, 'relu'), (64, 'tanh'), (7, 'softmax')]\n",
      "Transferring weights for layer: ((64, 'tanh'), (7, 'softmax'))\n",
      "validation accuracy:  0.9945015673981191\n",
      "------------------------------------------------------\n",
      "Architecture:  [(128, 'elu'), (7, 'softmax')]\n",
      "Transferring weights for layer: ((128, 'elu'), (7, 'softmax'))\n",
      "validation accuracy:  0.053448275862068975\n",
      "------------------------------------------------------\n",
      "Architecture:  [(128, 'elu'), (256, 'sigmoid'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (128, 'elu'))\n",
      "Transferring weights for layer: ((256, 'sigmoid'), (7, 'softmax'))\n",
      "validation accuracy:  0.8347617554858935\n",
      "------------------------------------------------------\n",
      "Architecture:  [(512, 'sigmoid'), (64, 'tanh'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (512, 'sigmoid'))\n",
      "Transferring weights for layer: ((64, 'tanh'), (7, 'softmax'))\n",
      "validation accuracy:  0.7855172413793106\n",
      "------------------------------------------------------\n",
      "TRAINING CONTROLLER...\n",
      "------------------------------------------------------------------\n",
      "                       CONTROLLER EPOCH: 5\n",
      "------------------------------------------------------------------\n",
      "GENERATING ARCHITECTURE SAMPLES...\n",
      "------------------------------------------------------\n",
      "Architecture:  [(8, 'tanh'), (64, 'sigmoid'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (8, 'tanh'))\n",
      "Transferring weights for layer: ((64, 'sigmoid'), (7, 'softmax'))\n",
      "validation accuracy:  0.9884890282131661\n",
      "------------------------------------------------------\n",
      "Architecture:  [(32, 'sigmoid'), (64, 'sigmoid'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (32, 'sigmoid'))\n",
      "Transferring weights for layer: ((64, 'sigmoid'), (7, 'softmax'))\n",
      "validation accuracy:  0.9937084639498434\n",
      "------------------------------------------------------\n",
      "Architecture:  [(64, 'tanh'), (32, 'tanh'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (64, 'tanh'))\n",
      "Transferring weights for layer: ((32, 'tanh'), (7, 'softmax'))\n",
      "validation accuracy:  0.9702257053291535\n",
      "------------------------------------------------------\n",
      "Architecture:  [(16, 'elu'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (16, 'elu'))\n",
      "validation accuracy:  0.9932037617554859\n",
      "------------------------------------------------------\n",
      "Architecture:  [(128, 'tanh'), (32, 'sigmoid'), (7, 'softmax')]\n",
      "validation accuracy:  0.9619561128526647\n",
      "------------------------------------------------------\n",
      "Architecture:  [(64, 'relu'), (32, 'sigmoid'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (64, 'relu'))\n",
      "Transferring weights for layer: ((32, 'sigmoid'), (7, 'softmax'))\n",
      "validation accuracy:  0.993498432601881\n",
      "------------------------------------------------------\n",
      "Architecture:  [(16, 'tanh'), (128, 'elu'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (16, 'tanh'))\n",
      "Transferring weights for layer: ((128, 'elu'), (7, 'softmax'))\n",
      "validation accuracy:  0.9853510971786834\n",
      "------------------------------------------------------\n",
      "Architecture:  [(64, 'relu'), (32, 'relu'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (64, 'relu'))\n",
      "Transferring weights for layer: ((32, 'relu'), (7, 'softmax'))\n",
      "validation accuracy:  0.000689655172413793\n",
      "------------------------------------------------------\n",
      "Architecture:  [(128, 'elu'), (32, 'sigmoid'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (128, 'elu'))\n",
      "Transferring weights for layer: ((32, 'sigmoid'), (7, 'softmax'))\n",
      "validation accuracy:  0.8563573667711598\n",
      "------------------------------------------------------\n",
      "Architecture:  [(64, 'relu'), (8, 'tanh'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (64, 'relu'))\n",
      "Transferring weights for layer: ((8, 'tanh'), (7, 'softmax'))\n",
      "validation accuracy:  0.9963354231974922\n",
      "------------------------------------------------------\n",
      "TRAINING CONTROLLER...\n",
      "------------------------------------------------------------------\n",
      "                       CONTROLLER EPOCH: 6\n",
      "------------------------------------------------------------------\n",
      "GENERATING ARCHITECTURE SAMPLES...\n",
      "------------------------------------------------------\n",
      "Architecture:  [(512, 'elu'), (512, 'sigmoid'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (512, 'elu'))\n",
      "Transferring weights for layer: ((512, 'sigmoid'), (7, 'softmax'))\n",
      "validation accuracy:  0.7889655172413794\n",
      "------------------------------------------------------\n",
      "Architecture:  [(16, 'elu'), (16, 'elu'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (16, 'elu'))\n",
      "Transferring weights for layer: ((16, 'elu'), (7, 'softmax'))\n",
      "validation accuracy:  0.9932068965517242\n",
      "------------------------------------------------------\n",
      "Architecture:  [(512, 'elu'), (128, 'sigmoid'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (512, 'elu'))\n",
      "Transferring weights for layer: ((128, 'sigmoid'), (7, 'softmax'))\n",
      "validation accuracy:  0.78623197492163\n",
      "------------------------------------------------------\n",
      "Architecture:  [(16, 'sigmoid'), (512, 'elu'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (16, 'sigmoid'))\n",
      "Transferring weights for layer: ((512, 'elu'), (7, 'softmax'))\n",
      "validation accuracy:  0.9727210031347961\n",
      "------------------------------------------------------\n",
      "Architecture:  [(32, 'relu'), (64, 'relu'), (7, 'softmax')]\n",
      "validation accuracy:  0.7843103448275861\n",
      "------------------------------------------------------\n",
      "Architecture:  [(128, 'elu'), (256, 'tanh'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (128, 'elu'))\n",
      "Transferring weights for layer: ((256, 'tanh'), (7, 'softmax'))\n",
      "validation accuracy:  0.7425078369905956\n",
      "------------------------------------------------------\n",
      "Architecture:  [(128, 'elu'), (512, 'elu'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (128, 'elu'))\n",
      "Transferring weights for layer: ((512, 'elu'), (7, 'softmax'))\n",
      "validation accuracy:  0.06258620689655173\n",
      "------------------------------------------------------\n",
      "Architecture:  [(8, 'relu'), (64, 'relu'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (8, 'relu'))\n",
      "Transferring weights for layer: ((64, 'relu'), (7, 'softmax'))\n",
      "validation accuracy:  0.7812068965517242\n",
      "------------------------------------------------------\n",
      "Architecture:  [(128, 'tanh'), (16, 'relu'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (128, 'tanh'))\n",
      "Transferring weights for layer: ((16, 'relu'), (7, 'softmax'))\n",
      "validation accuracy:  0.9953793103448276\n",
      "------------------------------------------------------\n",
      "Architecture:  [(128, 'tanh'), (256, 'elu'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (128, 'tanh'))\n",
      "Transferring weights for layer: ((256, 'elu'), (7, 'softmax'))\n",
      "validation accuracy:  0.7901724137931034\n",
      "------------------------------------------------------\n",
      "TRAINING CONTROLLER...\n",
      "------------------------------------------------------------------\n",
      "                       CONTROLLER EPOCH: 7\n",
      "------------------------------------------------------------------\n",
      "GENERATING ARCHITECTURE SAMPLES...\n",
      "------------------------------------------------------\n",
      "Architecture:  [(256, 'relu'), (128, 'sigmoid'), (7, 'softmax')]\n",
      "Transferring weights for layer: ((128, 'sigmoid'), (7, 'softmax'))\n",
      "validation accuracy:  0.7874137931034483\n",
      "------------------------------------------------------\n",
      "Architecture:  [(64, 'tanh'), (128, 'elu'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (64, 'tanh'))\n",
      "Transferring weights for layer: ((128, 'elu'), (7, 'softmax'))\n",
      "validation accuracy:  0.9759561128526645\n",
      "------------------------------------------------------\n",
      "Architecture:  [(8, 'elu'), (32, 'relu'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (8, 'elu'))\n",
      "Transferring weights for layer: ((32, 'relu'), (7, 'softmax'))\n",
      "validation accuracy:  0.9363291536050157\n",
      "------------------------------------------------------\n",
      "Architecture:  [(32, 'relu'), (8, 'sigmoid'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (32, 'relu'))\n",
      "Transferring weights for layer: ((8, 'sigmoid'), (7, 'softmax'))\n",
      "validation accuracy:  0.9954263322884013\n",
      "------------------------------------------------------\n",
      "Architecture:  [(32, 'elu'), (128, 'relu'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (32, 'elu'))\n",
      "validation accuracy:  0.7748275862068965\n",
      "------------------------------------------------------\n",
      "Architecture:  [(32, 'elu'), (64, 'sigmoid'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (32, 'elu'))\n",
      "Transferring weights for layer: ((64, 'sigmoid'), (7, 'softmax'))\n",
      "validation accuracy:  0.9955862068965519\n",
      "------------------------------------------------------\n",
      "Architecture:  [(32, 'relu'), (128, 'elu'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (32, 'relu'))\n",
      "Transferring weights for layer: ((128, 'elu'), (7, 'softmax'))\n",
      "validation accuracy:  0.0\n",
      "------------------------------------------------------\n",
      "Architecture:  [(8, 'elu'), (16, 'sigmoid'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (8, 'elu'))\n",
      "Transferring weights for layer: ((16, 'sigmoid'), (7, 'softmax'))\n",
      "validation accuracy:  0.941\n",
      "------------------------------------------------------\n",
      "Architecture:  [(512, 'sigmoid'), (64, 'sigmoid'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (512, 'sigmoid'))\n",
      "Transferring weights for layer: ((64, 'sigmoid'), (7, 'softmax'))\n",
      "validation accuracy:  0.7808620689655171\n",
      "------------------------------------------------------\n",
      "Architecture:  [(64, 'sigmoid'), (64, 'elu'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (64, 'sigmoid'))\n",
      "Transferring weights for layer: ((64, 'elu'), (7, 'softmax'))\n",
      "validation accuracy:  0.9895830721003135\n",
      "------------------------------------------------------\n",
      "TRAINING CONTROLLER...\n",
      "------------------------------------------------------------------\n",
      "                       CONTROLLER EPOCH: 8\n",
      "------------------------------------------------------------------\n",
      "GENERATING ARCHITECTURE SAMPLES...\n",
      "------------------------------------------------------\n",
      "Architecture:  [(256, 'sigmoid'), (128, 'elu'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (256, 'sigmoid'))\n",
      "Transferring weights for layer: ((128, 'elu'), (7, 'softmax'))\n",
      "validation accuracy:  0.7825862068965517\n",
      "------------------------------------------------------\n",
      "Architecture:  [(64, 'elu'), (64, 'relu'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (64, 'elu'))\n",
      "Transferring weights for layer: ((64, 'relu'), (7, 'softmax'))\n",
      "validation accuracy:  0.781896551724138\n",
      "------------------------------------------------------\n",
      "Architecture:  [(128, 'relu'), (8, 'sigmoid'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (128, 'relu'))\n",
      "Transferring weights for layer: ((8, 'sigmoid'), (7, 'softmax'))\n",
      "validation accuracy:  0.7748275862068965\n",
      "------------------------------------------------------\n",
      "Architecture:  [(8, 'relu'), (16, 'tanh'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (8, 'relu'))\n",
      "Transferring weights for layer: ((16, 'tanh'), (7, 'softmax'))\n",
      "validation accuracy:  0.848153605015674\n",
      "------------------------------------------------------\n",
      "Architecture:  [(16, 'tanh'), (32, 'elu'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (16, 'tanh'))\n",
      "Transferring weights for layer: ((32, 'elu'), (7, 'softmax'))\n",
      "validation accuracy:  0.9836050156739812\n",
      "------------------------------------------------------\n",
      "Architecture:  [(16, 'sigmoid'), (64, 'sigmoid'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (16, 'sigmoid'))\n",
      "Transferring weights for layer: ((64, 'sigmoid'), (7, 'softmax'))\n",
      "validation accuracy:  0.9904608150470219\n",
      "------------------------------------------------------\n",
      "Architecture:  [(64, 'sigmoid'), (32, 'sigmoid'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (64, 'sigmoid'))\n",
      "Transferring weights for layer: ((32, 'sigmoid'), (7, 'softmax'))\n",
      "validation accuracy:  0.9891880877742947\n",
      "------------------------------------------------------\n",
      "Architecture:  [(512, 'relu'), (64, 'elu'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (512, 'relu'))\n",
      "Transferring weights for layer: ((64, 'elu'), (7, 'softmax'))\n",
      "validation accuracy:  0.00017241379310344826\n",
      "------------------------------------------------------\n",
      "Architecture:  [(16, 'tanh'), (512, 'relu'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (16, 'tanh'))\n",
      "Transferring weights for layer: ((512, 'relu'), (7, 'softmax'))\n",
      "validation accuracy:  0.9796394984326019\n",
      "------------------------------------------------------\n",
      "Architecture:  [(64, 'tanh'), (512, 'relu'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (64, 'tanh'))\n",
      "Transferring weights for layer: ((512, 'relu'), (7, 'softmax'))\n",
      "validation accuracy:  0.7884482758620689\n",
      "------------------------------------------------------\n",
      "TRAINING CONTROLLER...\n",
      "------------------------------------------------------------------\n",
      "                       CONTROLLER EPOCH: 9\n",
      "------------------------------------------------------------------\n",
      "GENERATING ARCHITECTURE SAMPLES...\n",
      "------------------------------------------------------\n",
      "Architecture:  [(16, 'sigmoid'), (64, 'elu'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (16, 'sigmoid'))\n",
      "Transferring weights for layer: ((64, 'elu'), (7, 'softmax'))\n",
      "validation accuracy:  0.9867868338557995\n",
      "------------------------------------------------------\n",
      "Architecture:  [(16, 'relu'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (16, 'relu'))\n",
      "Transferring weights for layer: ((16, 'relu'), (7, 'softmax'))\n",
      "validation accuracy:  0.7904043887147335\n",
      "------------------------------------------------------\n",
      "Architecture:  [(128, 'relu'), (16, 'relu'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (128, 'relu'))\n",
      "Transferring weights for layer: ((16, 'relu'), (7, 'softmax'))\n",
      "validation accuracy:  0.7886206896551725\n",
      "------------------------------------------------------\n",
      "Architecture:  [(512, 'elu'), (16, 'relu'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (512, 'elu'))\n",
      "Transferring weights for layer: ((16, 'relu'), (7, 'softmax'))\n",
      "validation accuracy:  0.7877586206896552\n",
      "------------------------------------------------------\n",
      "Architecture:  [(32, 'sigmoid'), (32, 'sigmoid'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (32, 'sigmoid'))\n",
      "Transferring weights for layer: ((32, 'sigmoid'), (7, 'softmax'))\n",
      "validation accuracy:  0.9892225705329152\n",
      "------------------------------------------------------\n",
      "Architecture:  [(8, 'relu'), (64, 'elu'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (8, 'relu'))\n",
      "Transferring weights for layer: ((64, 'elu'), (7, 'softmax'))\n",
      "validation accuracy:  0.0008620689655172414\n",
      "------------------------------------------------------\n",
      "Architecture:  [(64, 'relu'), (64, 'sigmoid'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (64, 'relu'))\n",
      "Transferring weights for layer: ((64, 'sigmoid'), (7, 'softmax'))\n",
      "validation accuracy:  0.9930815047021943\n",
      "------------------------------------------------------\n",
      "Architecture:  [(8, 'relu'), (512, 'relu'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (8, 'relu'))\n",
      "Transferring weights for layer: ((512, 'relu'), (7, 'softmax'))\n",
      "validation accuracy:  0.7793103448275863\n",
      "------------------------------------------------------\n",
      "Architecture:  [(128, 'elu'), (64, 'sigmoid'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (128, 'elu'))\n",
      "Transferring weights for layer: ((64, 'sigmoid'), (7, 'softmax'))\n",
      "validation accuracy:  0.20777742946708463\n",
      "------------------------------------------------------\n",
      "Architecture:  [(16, 'relu'), (64, 'relu'), (7, 'softmax')]\n",
      "Transferring weights for layer: ('input', (16, 'relu'))\n",
      "Transferring weights for layer: ((64, 'relu'), (7, 'softmax'))\n",
      "validation accuracy:  0.7877586206896552\n",
      "------------------------------------------------------\n",
      "TRAINING CONTROLLER...\n",
      "Top 5 Architectures:\n",
      "Architecture [(16, 'sigmoid'), (7, 'softmax')]\n",
      "Validation Accuracy: 0.9970564263322885\n",
      "Architecture [(64, 'sigmoid'), (128, 'tanh'), (7, 'softmax')]\n",
      "Validation Accuracy: 0.9963824451410659\n",
      "Architecture [(64, 'relu'), (8, 'tanh'), (7, 'softmax')]\n",
      "Validation Accuracy: 0.9963354231974922\n",
      "Architecture [(32, 'elu'), (64, 'sigmoid'), (7, 'softmax')]\n",
      "Validation Accuracy: 0.9955862068965519\n",
      "Architecture [(32, 'sigmoid'), (8, 'relu'), (7, 'softmax')]\n",
      "Validation Accuracy: 0.9955485893416928\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('DATASETS/shuttle.csv')\n",
    "x = data.drop('class', axis=1, inplace=False).values\n",
    "y = pd.get_dummies(data['class']).values\n",
    "\n",
    "nas_object = MLPNAS(x, y)\n",
    "data = nas_object.search()\n",
    "\n",
    "get_top_n_architectures(TOP_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv('DATASETS/shuttle.csv').iloc[:,1:]\n",
    "\n",
    "x = data2.drop('class', axis=1, inplace=False).values\n",
    "y = pd.get_dummies(data2['class']).values\n",
    "\n",
    "x_2 = data2.drop('class', axis=1, inplace=False).values\n",
    "data2['class'] = pd.Categorical(data2['class'])\n",
    "y_2 = data2['class'].cat.codes.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "np.random.seed(123)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, \n",
    "                                                    train_size = 0.70, test_size = 0.30, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "## XGB Split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "np.random.seed(123)\n",
    "X_train_xgb, X_test_xgb, y_train_xgb, y_test_xgb = train_test_split(x_2, y_2, \n",
    "                                                    train_size = 0.70, test_size = 0.30, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x[0].shape\n",
    "num_classes = 7\n",
    "\n",
    "# Architecture [(16, 'sigmoid'), (7, 'softmax')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(16, input_shape=input_shape, activation='sigmoid'))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36540 samples, validate on 4060 samples\n",
      "Epoch 1/10\n",
      "36540/36540 [==============================] - 22s 600us/step - loss: 0.5954 - acc: 0.8465 - val_loss: 0.3840 - val_acc: 0.8921\n",
      "Epoch 2/10\n",
      "36540/36540 [==============================] - 3s 74us/step - loss: 0.2930 - acc: 0.9094 - val_loss: 0.2452 - val_acc: 0.9106\n",
      "Epoch 3/10\n",
      "36540/36540 [==============================] - 3s 70us/step - loss: 0.2037 - acc: 0.9143 - val_loss: 0.1821 - val_acc: 0.9143\n",
      "Epoch 4/10\n",
      "36540/36540 [==============================] - 3s 70us/step - loss: 0.1528 - acc: 0.9554 - val_loss: 0.1375 - val_acc: 0.9640\n",
      "Epoch 5/10\n",
      "36540/36540 [==============================] - 3s 70us/step - loss: 0.1152 - acc: 0.9744 - val_loss: 0.1063 - val_acc: 0.9884\n",
      "Epoch 6/10\n",
      "36540/36540 [==============================] - 3s 69us/step - loss: 0.0906 - acc: 0.9918 - val_loss: 0.0843 - val_acc: 0.9901\n",
      "Epoch 7/10\n",
      "36540/36540 [==============================] - 3s 70us/step - loss: 0.0721 - acc: 0.9937 - val_loss: 0.0655 - val_acc: 0.9941\n",
      "Epoch 8/10\n",
      "36540/36540 [==============================] - 3s 69us/step - loss: 0.0528 - acc: 0.9948 - val_loss: 0.0489 - val_acc: 0.9938\n",
      "Epoch 9/10\n",
      "36540/36540 [==============================] - 3s 70us/step - loss: 0.0429 - acc: 0.9949 - val_loss: 0.0378 - val_acc: 0.9953\n",
      "Epoch 10/10\n",
      "36540/36540 [==============================] - 3s 70us/step - loss: 0.0358 - acc: 0.9953 - val_loss: 0.0319 - val_acc: 0.9958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24a3271ccc0>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=len(data), verbose=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17400/17400 [==============================] - 3s 167us/step\n"
     ]
    }
   ],
   "source": [
    "test_results = model.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results - Loss: 0.029165089244301293 - Accuracy: 0.9960344827586207%\n"
     ]
    }
   ],
   "source": [
    "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "predOut = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [np.argmax(y) for y in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13670,     0,    11,     0,     1,     0,     0],\n",
       "       [    0,     0,     0,     0,     0,     0,     0],\n",
       "       [    3,     0,     9,     0,     1,     0,     2],\n",
       "       [    1,     7,    34,  2656,     0,     0,     0],\n",
       "       [    3,     2,     0,     1,   996,     3,     0],\n",
       "       [    0,     0,     0,     0,     0,     0,     0],\n",
       "       [    0,     0,     0,     0,     0,     0,     0]], dtype=int64)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(predOut, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9960344827586207"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true, predOut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_xgb, X_test_xgb, y_train_xgb, y_test_xgb\n",
    "defaultClassifier = xgb.XGBClassifier().fit(X_train_xgb, y_train_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaultPred = defaultClassifier.predict(X_test_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13676,     0,     0,     0,     0,     0,     0],\n",
       "       [    0,     9,     0,     0,     0,     0,     0],\n",
       "       [    1,     0,    54,     0,     0,     0,     0],\n",
       "       [    0,     0,     0,  2657,     0,     0,     0],\n",
       "       [    0,     0,     0,     0,   998,     0,     0],\n",
       "       [    0,     0,     0,     0,     0,     3,     0],\n",
       "       [    0,     0,     0,     0,     0,     0,     2]], dtype=int64)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(defaultPred, y_test_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999425287356322"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test_xgb, defaultPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
